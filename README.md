# Juan Carlos Cruz â€“ Code Portfolio
##### Note: Develop the Portfolio into a fully functioning website

### Description
Attached are a sample of works and projects done from my class and my free time at home!

## [Project 1: Image Classifier for the MNIST Fashion Dataset](https://github.com/jmcruz14/jay-cruz-code-folio-2022/tree/main/PROJECT-1)
* Built a program that predicts the type of clothing shown on-screen as part of a requirement for a Data Science and Analytics course
* Employed the tensorflow python module to import the image and build the appropriate convolutional neural network for the project
* Additional modules were pandas, numpy, and matplotlib
* Utilized 8 neural network layers of 5 types (Conv2D, MaxPool2D, Flatten, Dense, Dropout) for the model to be trained for 10 iterations with a stop function in case the value change for 2 iterations remained the same
* Sample of predicted results were printed out via a Python list

![](/PROJECT-1/image-classifier-code-snippet.png)

## [Project 2: Predictive Model for Spam and Legit Messages](https://github.com/jmcruz14/jay-cruz-code-folio-2022/tree/main/PROJECT-2)
* Built a predictive model that determines whether a message is a 'spam' message or a legitimate one for a Data Science and Analytics course
* Dataset employed contained a sample of 5,572 SMS texts to be parsed over by the model
* Employed pandas, numpy, and tensorflow to clean up the data and tokenize into entries which were fed into a constructed Neural Network
* Neural Network was trained for 15 epochs before being tested for accuracy over a sample data obtained from 5,572 SMS texts

![](/PROJECT-2/spam-legit-confusionmatrix.png)

## [Project 3: Journal Entry Frequency Visualization](https://github.com/jmcruz14/jay-cruz-code-folio-2022/tree/main/PROJECT-3)
* Analyzed my own journal entry database containing data on over 350 entry titles, date and time of writing, and journal number written from 2014 to 2021
* Employed Python's matplotlib, seaborn, and pandas modules to generate, sort, and visualize the data in question
* Utilized aggregated bar graphs arranged vertically according to the hour of writing and horizontally according to the minute of writing to visually determine what times of the day I'd write about my day

![](/PROJECT-3/journalfreq_graph-smaller.png)

## [Project 4: Ramen Dataset Analysis](https://github.com/jmcruz14/jay-cruz-code-folio-2022/tree/main/PROJECT-4)
* Analyzed a sample dataset of Ramen reviews from all over the world for a Data Science and Analytics course
* Identified the frequency of countries with Top 10 Ramen products, the average rating of Ramen products according to style specialty, and the ratings distribution of Nissin Ramen products
* Utilized matplotlib, seaborn, and pandas modules for data visualization and cleaning

![](/PROJECT-4/ramen_rating_nissin-dist.png)
![](/PROJECT-4/ramen_rating_style.png)
![](/PROJECT-4/ramen_rating_top-10.png)
